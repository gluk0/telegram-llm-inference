telegram-llm-inference
===================

A simple telegram bot that uses a LLM to generate responses to messages from a public LLM API, transforming data from the LLM API into a more user-friendly format for telegram consumption. 

Key Components:
-------------
- Main bot runner (src/main.py)
- Bot implementation (src/bot/telegram_bot.py)
- Configuration management (src/config/settings.py)

Requirements:
------------
- Python 3.7+
- Telegram Bot Token
- Required Python packages (see requirements.txt)

To run the bot:
--------------
1. Set up your environment variables (TELEGRAM_BOT_TOKEN)
2. Install dependencies from requirements.txt
3. Run: python src/main.py

Structure: 
----------
ðŸ“¦ telegram-llm-inference
â”£ ðŸ“‚ src
â”ƒ â”£ ðŸ“‚ bot
â”ƒ â”ƒ â”— ðŸ“œ telegram_bot.py
â”ƒ â”£ ðŸ“‚ config
â”ƒ â”ƒ â”— ðŸ“œ settings.py
â”ƒ â”— ðŸ“œ main.py
â”£ ðŸ“œ .env
â”£ ðŸ“œ .gitignore
â”£ ðŸ“œ PROJECT.txt
â”£ ðŸ“œ README.md
â”— ðŸ“œ requirements.txt